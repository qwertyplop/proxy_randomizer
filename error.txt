2025-11-23 17:52:16.505 [info] ‚¨áÔ∏è Fetching config from https://files.catbox.moe/uhcn8q.enc...
2025-11-23 17:52:16.902 [info] ‚úÖ Remote config loaded and decrypted successfully.
2025-11-23 17:52:16.904 [info] üîí Admin Access: Attempting to find specific model 'gemini-2.5-pro'
2025-11-23 17:52:16.904 [info] [2025-11-23T17:52:16.505213] üöÄ ATTEMPTING REQUEST
2025-11-23 17:52:16.904 [info] Source: sillytavern
2025-11-23 17:52:16.904 [info] Provider: Vertex-Gemini | Model: gemini-2.5-pro
2025-11-23 17:52:16.904 [info] Base URL (Config): https://aiplatform.googleapis.com/v1/publishers/google/models
2025-11-23 17:52:16.904 [info] Target URL (Final): https://aiplatform.googleapis.com/v1/projects/gen-lang-client-0031641020/locations/global/publishers/google/models/gemini-2.5-pro:generateContent
2025-11-23 17:52:16.998 [error] Exception on /sillytavern/chat/completions [POST]
Traceback (most recent call last):
  File "/var/task/_vendor/flask/app.py", line 1455, in wsgi_app
    response = self.full_dispatch_request()
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/var/task/_vendor/flask/app.py", line 869, in full_dispatch_request
    rv = self.handle_user_exception(e)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/var/task/_vendor/flask_cors/extension.py", line 176, in wrapped_function
    return cors_after_request(app.make_response(f(*args, **kwargs)))
                                                ^^^^^^^^^^^^^^^^^^
  File "/var/task/_vendor/flask/app.py", line 867, in full_dispatch_request
    rv = self.dispatch_request()
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "/var/task/_vendor/flask/app.py", line 852, in dispatch_request
    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/var/task/api/index.py", line 1049, in sillytavern_chat_proxy
    return proxy_request("sillytavern", "/chat/completions")
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/var/task/api/index.py", line 954, in proxy_request
    json_body = convert_openai_to_vertex(json_body, model_config.get("id", ""))
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/var/task/api/index.py", line 596, in convert_openai_to_vertex
    system_prompt_text += content + "\n\n"
    ^^^^^^^^^^^^^^^^^^
UnboundLocalError: cannot access local variable 'system_prompt_text' where it is not associated with a value
2025-11-23 17:52:16.998 [info] 127.0.0.1 - - [23/Nov/2025 17:52:16] "POST /sillytavern/chat/completions HTTP/1.1" 500 -